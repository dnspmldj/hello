# -*- coding: utf-8 -*-
"""DEJOSE_Midterm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PrWYnpxOiPmlWDfaovNbS8uN8zcXq98K

##MIDTERM EXAM

De Jose, Dennisse Pamela R. <BR>
CPE 019 - CPE31S1

##MLP Model
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
import os
import cv2
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from keras.optimizers import Adadelta
import matplotlib.pyplot as plt
from keras.callbacks import ModelCheckpoint, LearningRateScheduler

root_folder = '/content/drive/MyDrive/Multi-classWeatherDataset'

images = []
labels = []

class_mapping = {}
label_counter = 0

img_height, img_width, num_channels = 224, 224, 3

def imageprocessing(image_path):
    image = cv2.imread(image_path)
    if image is not None:
        image = cv2.resize(image, (img_height, img_width))
        image = image / 255.0
        return image
    else:
        return None

for class_name in os.listdir(root_folder):
    class_path = os.path.join(root_folder, class_name)
    if os.path.isdir(class_path):
        class_mapping[class_name] = label_counter
        label_counter += 1

        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)
            imageprocess = imageprocessing(image_path)
            if imageprocess is not None:
                images.append(imageprocess)
                labels.append(class_mapping[class_name])

X = np.array(images)
y = np.array(labels)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

num_classes = len(class_mapping)

y_train_encoded = keras.utils.to_categorical(y_train, num_classes=num_classes)
y_test_encoded = keras.utils.to_categorical(y_test, num_classes=num_classes)

model = keras.Sequential([layers.Flatten(input_shape=(img_height, img_width, num_channels)),layers.Dense(128, activation='relu'),layers.Dropout(0.2),layers.Dense(num_classes, activation='softmax')])

model.compile(optimizer=Adadelta(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

checkpoint = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)

def time_based_decay(epoch, lr):
    return lr / (1 + epoch)

history = model.fit(X_train, y_train_encoded, epochs=10, batch_size=20, validation_data=(X_test, y_test_encoded), callbacks=[checkpoint])

model.save("Weathers.h5")

model_json = model.to_json()
json_file_path = "Weathers.json"
with open(json_file_path, "w") as json_file:
    json_file.write(model_json)

test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

import tensorflow as tf
import os
import cv2
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import Sequential
from keras.optimizers import Adam
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder
from keras.layers import Dense, Dropout, Flatten
from sklearn.model_selection import train_test_split
from tensorflow.keras.metrics import categorical_crossentropy
from keras.callbacks import ModelCheckpoint, LearningRateScheduler

seed = 7
np.random.seed(seed)

root_folder = '/content/drive/MyDrive/Multi-classWeatherDataset'

labels = []
images = []
class_mapping = {}
label_counter = 0

for class_name in os.listdir(root_folder):
    class_path = os.path.join(root_folder, class_name)
    if os.path.isdir(class_path):
        class_mapping[class_name] = label_counter
        label_counter += 1

        for image_filename in os.listdir(class_path):
            image_path = os.path.join(class_path, image_filename)
            try:
                image = cv2.imread(image_path)
                if image is not None:
                    image = cv2.resize(image, (250, 250))
                    image = image / 255.0
                    images.append(image)
                    labels.append(class_mapping[class_name])
            except Exception as e:
                print(f"NoImage {image_path}: {str(e)}")

X = np.array(images)
y = np.array(labels)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)



model_json_file = '/content/Weathers.json'
with open(model_json_file, 'r') as json_file:
    loaded_model_json = json_file.read()

loaded_model = tf.keras.models.model_from_json(loaded_model_json)
loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model_weights_file = '/content/Weathers.h5'
loaded_model.load_weights(model_weights_file)

test_image_paths = ['/content/drive/MyDrive/Multi-classWeatherDataset/Cloudy/cloudyko.png',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Rain/rainyday.jpg',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Shine/sunshining.jpg',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Sunrise/sunnrising.jpg']

img_size = (224, 224)
channels = 3
class_labels = ['Rain','Sunrise', 'Cloudy','Shining']

for test_image_path in test_image_paths:

    test_image = cv2.imread(test_image_path)
    test_image = cv2.resize(test_image, img_size)
    test_image = test_image / 255.0


    test_image = np.reshape(test_image, (1, img_size[0], img_size[1], channels))


    predictions = loaded_model.predict(test_image)


    predicted_class = np.argmax(predictions, axis=1)
    predicted_text = class_labels[predicted_class[0]]


    output_image = test_image[0].copy()
    font = cv2.FONT_ITALIC
    font_scale = 1
    font_thickness = 2
    text_size = cv2.getTextSize(predicted_text, font, font_scale, font_thickness)[0]
    text_x = (output_image.shape[1] - text_size[0]) // 2
    text_y = output_image.shape[0] - 10
    cv2.putText(output_image, predicted_text, (text_x, text_y), font, font_scale, (0, 255, 0), font_thickness)


    output_image = (output_image * 255).astype(np.uint8)


    plt.imshow(cv2.cvtColor(output_image, cv2.COLOR_BGR2RGB))
    plt.title(predicted_text)
    plt.axis('off')
    plt.show()

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define num_classes
num_classes = 4

model = Sequential([Conv2D(22, (3, 3), activation='relu', input_shape=(imageH, imageW, channells)),
                    MaxPooling2D((2, 2)),
                    Conv2D(54, (3, 3), activation='relu'),
                    MaxPooling2D((2, 2)),
                    Flatten(),
                    Dense(128, activation='relu'),
                    Dropout(0.2),
                    Dense(num_classes, activation='softmax')])

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

"""##CNN MODEL"""

import os
import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow import keras
from tensorflow.keras import layers
from keras.callbacks import ModelCheckpoint
from keras.optimizers import Adadelta
from sklearn.model_selection import train_test_split

root_folder = '/content/drive/MyDrive/Multi-classWeatherDataset'
images = []
labels = []
class_mapping = {}
label_counter = 0
imageH, imageW, channells = 250, 250, 3

def imageprocess(image_path):
    images = cv2.imread(image_path)
    if images is not None:
        images = cv2.resize(images, (imageH, imageW))
        images = images / 255.0
        return images
    else:
      return None
for class_name in os.listdir(root_folder):
    class_path = os.path.join(root_folder, class_name)
    if os.path.isdir(class_path):
        class_mapping[class_name] = label_counter
        label_counter += 1

        for imagename in os.listdir(class_path):
            image_path = os.path.join(class_path, imagename)
            imageprocessing = imageprocess(image_path)
            if imageprocessing is not None:
                images.append(imageprocessing)
                labels.append(class_mapping[class_name])

X = np.array(images)
y = np.array(labels)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
num_classes = len(class_mapping)
class_counts = np.bincount(y_train)
total_samples = len(y_train)
class_weights = total_samples / (num_classes * class_counts + 1e-6)
y_train_encoded = keras.utils.to_categorical(y_train, num_classes=num_classes)
y_test_encoded = keras.utils.to_categorical(y_test, num_classes=num_classes)
pretrained_model = keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(imageH, imageW, channells))


x = layers.Flatten()(pretrained_model.output)
x = layers.Dense(64, activation='relu')(x)
x = layers.Dropout(0.2)(x)
x = layers.Dense(128, activation='relu')(x)
x = layers.Dropout(0.2)(x)
output = layers.Dense(num_classes, activation='softmax')(x)

model = keras.Model(inputs=pretrained_model.input, outputs=output)
model.compile(optimizer=Adadelta(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

CP = ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=2)
history = model.fit(X_train, y_train_encoded, epochs=15, batch_size=30, validation_data=(X_test, y_test_encoded),
                    class_weight=dict(enumerate(class_weights)), callbacks=[CP])

model.save("WeathersCNN.h5")

model_json = model.to_json()
json_file_path = "WeathersCNN.json"
with open(json_file_path, "w") as json_file:
    json_file.write(model_json)

test_loss, test_accuracy = model.evaluate(X_test, y_test_encoded)
print(f"Loss: {test_loss}")
print(f"Accuracy: {test_accuracy}")

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
print(class_mapping)

import tensorflow as tf
import cv2
import numpy as np
from tensorflow import keras
model = keras.models.load_model('WeathersCNN.h5')
img_height, img_width, num_channels = 250, 250, 3

def imageprocess(image_path):
    image = cv2.imread(image_path)
    if image is not None:
        image = cv2.resize(image, (img_height, img_width))
        image = image / 255.0
        return image
    else:
        return None

new_image_paths = ['/content/drive/MyDrive/Multi-classWeatherDataset/Cloudy/cloudy123.png',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Rain/rain192.jpg',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Shine/shine1.jpg',
                    '/content/drive/MyDrive/Multi-classWeatherDataset/Sunrise/sunrise19.jpg']


for image_path in new_image_paths:
    imageprocessing = imageprocess(image_path)
    if imageprocessing is not None:
        imageprocessing = (imageprocessing * 255).astype(np.uint8)  # Fix the typo here
        imageprocessing = cv2.cvtColor(imageprocessing, cv2.COLOR_BGR2RGB)
        imageprocessing = imageprocessing.astype(np.float32) / 255.0
        imageprocessing = (imageprocessing * 255).astype(np.uint8)
        saveimage = np.expand_dims(imageprocessing, axis=0).astype(np.float32)
        predictions = model.predict(saveimage)
        class_mapping = {0: 'Cloud',
                         1: 'Rain',
                         2: 'Shine',
                         3: 'Sunrise', }

        predicted_class = class_mapping[np.argmax(predictions)]
        actual_class = os.path.basename(os.path.dirname(image_path))
        confidence = np.max(predictions)
        if predicted_class == actual_class:
            result = "True"
        else:
            result = "False"

        plt.imshow(imageprocessing)  # Fix the variable name here
        plt.title(f"Predicted Class: {predicted_class}, Confidence: {confidence:.2f}, Result: {result}")
        plt.axis('off')
        plt.show()